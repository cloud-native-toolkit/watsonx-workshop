{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Retrieval Augmented Generation w/ Watson Discovery & watsonx.ai\n\nThis notebook introduces RAG (Retrieval Augmented Generation) by making use of several IBM tools including watsonx.ai to generate answers and garner insights from documents and Watson Discovery as an API to search and answer questions about business documents using custom natural language processing."}, {"metadata": {}, "cell_type": "markdown", "source": "This lab should take 30-40 minutes.\n\nBefore we begin lets start off by ensuring we have completed some pre-requisites; ensure you gave the following\n\n- IBM Cloud API key \n- Project ID associated with your watsonx instance\n- Project ID associated with your Watson Discovery instanace \n- Service URL for Watson Discovery instance\n\nYou can use the following support links if you need any help with the pre-requisites above\n\n- [Creating IBM Cloud API Key](https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui#create_user_key)\n- [Finding watsonx Project ID](https://www.ibm.com/docs/en/watsonx-as-a-service?topic=library-project-id)\n- [Finding Watson Discovery Project ID](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-getting-started)\n- [Determining Watson Discovery Service URL](https://cloud.ibm.com/apidocs/discovery-data?code=python#endpoint-cloud)\n    - Note this support link shows you the base url, you will need to find the instance url from resource list in the IBM Cloud dashboard."}, {"metadata": {}, "cell_type": "code", "source": "# Download dependencies\n\nimport sys\n!{sys.executable} -m pip install -q ibm_watson\n!{sys.executable} -m pip install -q ibm_cloud_sdk_core\n!{sys.executable} -m pip install -q ibm_watson_machine_learning\n!pip install python-dotenv==1.0.0\n", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: python-dotenv==1.0.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (1.0.0)\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Import the necessary packages\n\nfrom ibm_watson import DiscoveryV2\nfrom ibm_watson.discovery_v2 import QueryLargePassages\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator\nfrom ibm_cloud_sdk_core import IAMTokenManager\nfrom ibm_watson_machine_learning.foundation_models import Model\n", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Setting up authentication and Watson Discovery\n\nWatson Discovery is a cognitive search and content analytics engine that you can add to applications to identify patterns, \ntrends and actionable insights to drive better decision-making. For this lab, we will be making use of Watson Discovery \nto store, analyze, and search the documents which will act as a knowledge base for the question we will eventually be \nasking watsonx.ai.\n\nIf you are completing this lab in a workshop setting, a Watson Discovery instance with a collection of documents may \nalready be set-up for you; ask your lab instructor. If not, you can create your own Watson Discovery instance from \nIBM Cloud with your own collection of documents, for consistency of this lab you can find a link to the documents used \nfor this collections linked [here](https://github.com/ibm-build-lab/VAD-VAR-Workshop/tree/87155f66db7248994ff17fc0dfe80a3b99b64fc9/content/Watsonx/WatsonxAI/docs)."}, {"metadata": {}, "cell_type": "code", "source": "# Your IBM Cloud API key\napi_key = \"mXMwkYwWPgTl2ORNtFEfhCOlkOFQQt6f92hZITvDSKEy\"\n\n# Project ID of your watson discovery collection instance\ndiscovery_project_id = \"3f412ff2-5c0a-4cc8-9ae9-568672dcde0e\"\n\n# Service URL for your watson discovery instance\nservice_url = 'https://api.us-south.discovery.watson.cloud.ibm.com/instances/dea4a8e6-09d2-46cc-82d7-3d6820a2ac43'\n\n# Project ID of your watsonx project\nwatsonx_project_id = \"7dff0029-1f9b-47b4-87bc-79d0b4da0820\"\n\n# Create IBM IAM authenticator object using your IBM Cloud API Key\nauthenticator = IAMAuthenticator(api_key)\n\n# Create an Watson Discovery object using the authenticator object previously created\ndiscovery = DiscoveryV2(\n    version='2020-08-30',\n    authenticator=authenticator\n)\n\n# Set the Watson Discovery service url within our discovery object\ndiscovery.set_service_url(service_url)\nprint(\"done\")\n", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "done\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Natural language query for Watson Discovery collection\ndiscovery_question=\"What is the outstanding long term debt at the end of 2023?\"\n\ndef query_discovery(question):\n  passages = {\n    \"enabled\": True, \n    \"per_document\": True, \n    \"find_answers\": True,\n    \"max_per_document\": 1, \n    \"characters\": 500\n   }\n\n  query_large_passages_model = QueryLargePassages.from_dict(passages)\n\n  return discovery.query(\n          project_id=discovery_project_id,\n          natural_language_query=question,\n          passages=query_large_passages_model,\n          count=1\n      ).get_result()\n\n\ndiscovery_json = query_discovery(discovery_question)\nprint(\"done\")\n# print(discovery_json)", "execution_count": 11, "outputs": [{"output_type": "stream", "text": "done\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Watson Discovery returns a list of documents broken into passages from a given collection\n# We want to combine this passages so it can serve as a knowledge base that we provide to watsonx.ai\ndisc_results = []\ncombined_disc_results = []\nfor doc_index in range(len(discovery_json[\"results\"])):\n    for j in range(len(discovery_json[\"results\"][doc_index])):\n        passages = discovery_json[\"results\"][doc_index][\"document_passages\"]\n        disc_results = []\n        for item in passages:\n            item = item[\"passage_text\"].replace(\"<em>\",\"\")\n            item = item.replace(\"</em>\", \"\")\n            disc_results.append(item)\n    combined_disc_results.append(\"\\n\".join(disc_results))\nprint(\"done\")\nprint(\"Context to LLM : \")\nprint(combined_disc_results)", "execution_count": 21, "outputs": [{"output_type": "stream", "text": "done\nContext to LLM : \n['Net Investment Hedge Instruments The Company has designated non-derivative foreign currency denominated long-term debt and the related accrued interest as hedges of its net investment in certain foreign operations. Accordingly, the foreign currency translation of the debt instrument and accrued interest is recorded in accumulated other comprehensive loss, offsetting the foreign currency translation adjustment of the related net investment that is also recorded in accumulated other comprehensive loss. As of March 31, 2023, the Company had \u20ac2,250 million of outstanding long- term debt and approximately \u20ac42 million of accrued interest designated as non-derivative hedges of its net investment in certain foreign operations.']\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Get our API key and URL from .env\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\n#api_key = 'mXMwkYwWPgTl2ORNtFEfhCOlkOFQQt6f92hZITvDSKEy'\nibm_cloud_url = 'https://us-south.ml.cloud.ibm.com'\nproject_id = os.getenv(\"PROJECT_ID\", None)\n\nif api_key is None or ibm_cloud_url is None or project_id is None:\n    raise Exception(\"One or more environment variables are missing!\")\nelse:\n    creds = {\n        \"url\": ibm_cloud_url,\n        \"apikey\": api_key \n    }\nprint(\"Done getting env variables.\")", "execution_count": 12, "outputs": [{"output_type": "stream", "text": "Done getting env variables.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# LLM that we want to use with watsonx.ai\nmodel_id= \"google/flan-ul2\"\n\nendpoint= \"https://us-south.ml.cloud.ibm.com\"\n\n#access_token = ''\n\n#try:\n#  access_token = IAMTokenManager(\n#    apikey = api_key,\n#    url = \"https://iam.cloud.ibm.com/identity/token\"\n#  ).get_token()\n#except:\n#  print('Issue obtaining access token. Check variables?')\n\n#credentials = { \n#    \"url\"    : endpoint, \n#    \"token\" : access_token\n#}\n\n# watsonx.ai tuning parameters\ngen_params = {\n    \"DECODING_METHOD\" : \"greedy\",\n    \"MAX_NEW_TOKENS\" : 500,\n    \"MIN_NEW_TOKENS\" : 2,\n    \"STREAM\" : False,\n    \"TEMPERATURE\" : 1.7,\n    \"TOP_K\" : 50,\n    \"TOP_P\" : 1,\n    \"RANDOM_SEED\" : 10\n}\n\nmodel = Model( model_id, creds, gen_params, watsonx_project_id )\nprint(\"done\")\n", "execution_count": 13, "outputs": [{"output_type": "stream", "text": "done\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#######################################################################################\nprompt_template = \"\"\"\nArticle:\n###\n%s\n###\n\nAnswer the following question using only information from the article. \nAnswer in a complete sentence, with proper capitalization and punctuation. \nIf there is no good answer in the article, say \"I don't know\".\n\nQuestion: %s\nAnswer: \n\"\"\"\n\n#######################################################################################\ndef augment( template_in, context_in, query_in ):\n    return template_in % ( context_in,  query_in )\n\n\n#######################################################################################\nimport json\n\ndef generate( model_in, augmented_prompt_in ):\n    \n    generated_response = model_in.generate( augmented_prompt_in )\n\n    if ( \"results\" in generated_response ) \\\n       and ( len( generated_response[\"results\"] ) > 0 ) \\\n       and ( \"generated_text\" in generated_response[\"results\"][0] ):\n        return generated_response[\"results\"][0][\"generated_text\"]\n    else:\n        print( \"The model failed to generate an answer\" )\n        print( \"\\nDebug info:\\n\" + json.dumps( generated_response, indent=3 ) )\n        return \"\"\n\n\n########################################################################################\nimport re\n\ndef query_watsonx(question):\n    augmented_prompt = augment( prompt_template, combined_disc_results, question )\n    print(augmented_prompt)\n    output = generate( model, augmented_prompt )\n    if not re.match( r\"\\S+\", output ):\n        print( \"The model failed to generate an answer\")\n    print( \"\\nAnswer:\\n\" + output )\n\n\nquery_watsonx(discovery_question)\n\nprint(\"\\ndone\")\n", "execution_count": 22, "outputs": [{"output_type": "stream", "text": "\nArticle:\n###\n['Net Investment Hedge Instruments The Company has designated non-derivative foreign currency denominated long-term debt and the related accrued interest as hedges of its net investment in certain foreign operations. Accordingly, the foreign currency translation of the debt instrument and accrued interest is recorded in accumulated other comprehensive loss, offsetting the foreign currency translation adjustment of the related net investment that is also recorded in accumulated other comprehensive loss. As of March 31, 2023, the Company had \u20ac2,250 million of outstanding long- term debt and approximately \u20ac42 million of accrued interest designated as non-derivative hedges of its net investment in certain foreign operations.']\n###\n\nAnswer the following question using only information from the article. \nAnswer in a complete sentence, with proper capitalization and punctuation. \nIf there is no good answer in the article, say \"I don't know\".\n\nQuestion: What is the outstanding long term debt at the end of 2023?\nAnswer: \n\n\nAnswer:\n\u20ac2,250 million\n\ndone\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}